{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import glob\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from functions import *\n",
    "from inference_set import inference_set\n",
    "from cnn_model import SmallResNet18_Input64_Contrastive,OTCNN_Input64_with_pretrained_ResNet18_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CUDA if exists\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'CHECK devices {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example inputs\n",
    "sample_paths = sorted(glob.glob(\"Sample_data/*\"))\n",
    "input_images = np.empty([len(sample_paths),2,100,100])\n",
    "\n",
    "for idx, path in enumerate(tqdm(sample_paths)):\n",
    "    #print(path)\n",
    "    sample = np.load(path, allow_pickle = True)\n",
    "\n",
    "    input_images[idx] = sample\n",
    "    print(path)\n",
    "\n",
    "input_images.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for ResNet18 and VGG models\n",
    "img_size = 64\n",
    "BATCH_SIZE_eval = 1\n",
    "\n",
    "# Load contrastive-based model\n",
    "\n",
    "contrastive_model = 'pretrained_models/CT_Resnet18.pt'\n",
    "cont_model = SmallResNet18_Input64_Contrastive(num_classes=1, input_channel=2)\n",
    "cont_model = cont_model.to(device=device) \n",
    "cont_model.load_state_dict(torch.load(contrastive_model))\n",
    "\n",
    "\n",
    "\n",
    "# Load classification-based model\n",
    "cls_head_model = 'pretrained_models/CTN2N_ResNet18_OTCNN.pt'\n",
    "cont_model = cont_model.to(device=device) \n",
    "cont_model.load_state_dict(torch.load(contrastive_model))\n",
    "cont_model = cont_model.float()\n",
    "model = OTCNN_Input64_with_pretrained_ResNet18_contrastive(contrastive_extractor=cont_model,num_classes=2, input_channel=2)\n",
    "\n",
    "# Dataloader Settings\n",
    "scaler = 'std_scl'\n",
    "\n",
    "add_features = None\n",
    "\n",
    "\n",
    "test_eval = inference_set(images=input_images, transform=None, mode=add_features, local_scaler = scaler, default_size=img_size)#.to(device=device) #, transform=tranform_train change here\n",
    "test_loader_eval = DataLoader(test_eval, batch_size=BATCH_SIZE_eval, shuffle=False)\n",
    "\n",
    "model = model.to(device=device) \n",
    "model = model.double()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # model_name_from_path = os.path.basename(model_pt).split('_')#.replace('.','_')\n",
    "    # save_at = model_name_from_path[-1].split('.')[0]\n",
    "    # model_name_from_path = '_'.join(model_name_from_path[:-1]+[save_at])\n",
    "    print('Get Test set score.....')\n",
    "    pred_result = []\n",
    "\n",
    "    # ======================== Val score  ======================== #\n",
    "    for idx, imgs in enumerate(tqdm(test_loader_eval)):\n",
    "\n",
    "\n",
    "        images = imgs.to(device=device)\n",
    "        outputs = model(images)\n",
    "\n",
    "\n",
    "\n",
    "        if  torch.is_tensor(pred_result):\n",
    "            # target_result = torch.cat((target_result,labels.to(torch.int8)),0)\n",
    "            pred_result = torch.cat((pred_result,outputs),0)\n",
    "\n",
    "        else:\n",
    "            # target_result = labels.to(torch.int8)\n",
    "            pred_result = outputs\n",
    "\n",
    "    print(pred_result.size())\n",
    "\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    all_pred_result = softmax(torch.Tensor(pred_result))\n",
    "    all_pred_result = all_pred_result[:,1].cpu()\n",
    "\n",
    "\n",
    "    threshold = 0.5\n",
    "    all_pred_result= np.array(all_pred_result).reshape(-1)\n",
    "\n",
    "\n",
    "    pred_cls = np.where(all_pred_result>threshold,1,0)\n",
    "\n",
    "\n",
    "print(pred_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "fig, ax = plt.subplots(len(input_images),2, figsize=(5,10),sharex=True,sharey=True)\n",
    "\n",
    "for row in range(len(input_images)):\n",
    "\n",
    "    sample = input_images[row]\n",
    "\n",
    "    # sample = (sample-np.min(sample))/np.max(sample)\n",
    "    # sample /= np.max(sample)\n",
    "\n",
    "\n",
    "    # ax[row,0].imshow(sample[0], vmin=glob_min, vmax=glob_max, cmap='hot')\n",
    "    # ax[row,1].imshow(sample[1], vmin=glob_min, vmax=glob_max, cmap='hot')\n",
    "    \n",
    "\n",
    "    ax[row,0].imshow(sample[0], vmin=np.min(sample)*0.25, vmax=np.max(sample))\n",
    "    # ax[row,0].scatter(crop_size/2, crop_size/2, s=80, facecolors='none', edgecolors='y')\n",
    "\n",
    "    ax[row,1].imshow(sample[1], vmin=np.min(sample)*0.25, vmax=np.max(sample))\n",
    "    # ax[row,1].scatter(crop_size/2, crop_size/2, s=80, facecolors='none', edgecolors='y')\n",
    "\n",
    "\n",
    "    ax[row,0].axis('off')\n",
    "    ax[row,1].axis('off')\n",
    "\n",
    "    # if row == 0:\n",
    "    #     ax[row,0].set_title('Template',  fontsize=20)\n",
    "    #     ax[row,1].set_title('Science',  fontsize=20)\n",
    "    ax[row,0].set_title(f'Template: class {pred_cls[row]}',  fontsize=10)\n",
    "    ax[row,1].set_title(f'Science: class {pred_cls[row]}',  fontsize=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(f'Index = {index}, min = {np.min(sample)}, max = {np.max(sample)}')\n",
    "\n",
    "# fig.subplots_adjust(wspace=0,hspace=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asteroid_cls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
